---
title: Behavioural dynamics paper simulations
author: Pranav Minasandra
---

The analyses here can all be run by calling `python3 simulate.py`.

# Do classifiers cause false positives in detecting heavy tails?
We have caught heavy-tailed bout duration distributions in all behaviours, in
all individuals, and across three species. But since our behavioural sequences
are all inferred by classifiers of some sort, which might be susceptible to some
rate of error, is it possible that our results are just artefacts of this
schema?

To answer this question, I simulate numerous behavioural sequences where an
animal can perform two similar behaviours A and B. The
bout duration distributions for both are either (a) power-law or (b) exponentially distributed. 
In both cases, I then simulate a bimodal 'feature' with peaks corresponding to
each state. By controlling how separated the two peaks are, I can control the
error rate of a Bayes classifier, and reinterpret the true behavioural sequence
through the lens of a classifier prone to some error rate.

Now looking at these perceived behavioural sequences, I can measure the rate at
which power-laws are mistaken for exponential distributions and vice-versa.

# Why is there strange unexpected behaviour at error = 0.25?
After running the analysis above, most results made sense: I expected power-laws
to be destroyed by error prone classifiers (since power-laws depend on long
bouts). This is what happened. I also expected exponentials to continue to be
identified as exponentials. This also happened, except at error = 0.25, when all
exponentially distributed bout duration distributions were detected as truncated
power-laws. Why could this be happening?

Well, by simply running the analysis above for that error rate, we make a plot
of true bout duration distributions and those perceived by the classifier, and
see that (a) the perceived long bout probabilities are way lower than the true
ones as expected, and (b) long bouts are preferentially eliminated by the
classifier. This is an interesting simulation which makes us *MORE* confident in our
results from the paper!

# Do mixed pairs of exponentials seem power-law-esque?
In the last 6-10 years, there has been a lot of arguing that all power-laws are
simply 'mixtures of exponentials' perceived as power-laws. It's a solid argument
in some cases, but just how easy is it for a random mix of exponentials to look
power-law like?

Here we take pairs of exponentials with randomly generated parameter values, and
generate mixed distributions. In each such mixture, we ask whether data
generated by it best fits a power-law or truncated power-law distribution.
Turns out, no. It's not easy to generate heavy-tailed distributions this way.

# Do socially synchronising animals seem to have decreasing hazard functions in their bout duration distribution?
Probably the simplest sim to explain. We simulated a group of interacting
animals so that their probability of switching to a different behavior was
conditioned on how many individuals were doing the other behavior. It turns out
this rule does cause a decreasing hazard function.
